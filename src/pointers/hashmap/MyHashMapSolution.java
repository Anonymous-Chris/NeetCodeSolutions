package pointers.hashmap;

import java.util.Iterator;
import java.util.LinkedList;

public class MyHashMapSolution {
    //use linkedlist to solve this
    private static class Node{
        int key;
        int value;
        Node (int key, int value){
            this.key = key;
            this.value = value;
        }
    }
    private int SIZE = 1000;
    private LinkedList<Node>[] buckets;

    public MyHashMapSolution(){
        buckets = new LinkedList[SIZE];
        for(int i=0;i<SIZE;i++){
            buckets[i] = new LinkedList<>();
        }
    }

    private int hash(int key){
        return key%SIZE;
    }

    public void put(int key, int value) {
        int index = hash(key);
        for (Node node: buckets[index]){
            if(node.key == key){
                //update
                node.value = value;
                return;
            }
        }
        buckets[index].add(new Node(key, value));
    }

    public int get(int key) {
        int index = hash(key);
        for (Node node : buckets[index]) {
            if (node.key == key) {
                return node.value;
            }
        }
        return -1;
    }

    public void remove(int key) {
        int index = hash(key);
        Iterator<Node> it = buckets[index].iterator();
        while (it.hasNext()) {
            if (it.next().key == key) {
                it.remove();
                return;
            }
        }
    }
    }
/*
SIZE defines the number of buckets used to distribute keys and reduce collisions.
In Neetcode / LeetCode constraints: â‰¤ 10â´ operations
ğŸ“Œ In real HashMaps:
	â€¢	Size is often prime
	â€¢	Automatically resized

	â€¢	% SIZE ensures index stays in range [0, SIZE-1]
key = 1023
1023 % 1000 = 23
â†’ goes into bucket[23]

â¸»

â± Time Complexity (TC)

Let:
	â€¢	n = total number of key-value pairs stored
	â€¢	k = number of elements in a single bucket (due to collisions)
	â€¢	SIZE = number of buckets (1000)

ğŸ”¹ put(key, value)
	â€¢	Average Case: O(1)
	â€¢	Hashing gives direct bucket access
	â€¢	Few elements per bucket when well distributed
	â€¢	Worst Case: O(n)
	â€¢	All keys collide into the same bucket

â¸»

ğŸ”¹ get(key)
	â€¢	Average Case: O(1)
	â€¢	Direct bucket lookup + short linked list
	â€¢	Worst Case: O(n)
	â€¢	Full traversal of one bucket

â¸»

ğŸ”¹ remove(key)
	â€¢	Average Case: O(1)
	â€¢	Hash lookup + short linked list
	â€¢	Worst Case: O(n)
	â€¢	All elements in one bucket

â¸»

ğŸ”¹ Constructor MyHashMap()
	â€¢	Time: O(SIZE)
	â€¢	Initializing all buckets

â¸»

ğŸ§  Space Complexity (SC)

ğŸ”¹ Total Space
	â€¢	O(n + SIZE)

Breakdown:
	â€¢	n â†’ number of stored key-value pairs (Nodes)
	â€¢	SIZE â†’ fixed number of LinkedList buckets (1000)

Since SIZE is constant:
	â€¢	Effective Space Complexity: O(n)

â¸»

ğŸ“Š Summary Table

Operation	Avg TC	Worst TC	SC
put	        O(1)	O(n)	O(1)
get	        O(1)	O(n)	O(1)
remove	    O(1)	O(n)	O(1)
overall	    â€”	    â€”	    O(n)


â¸»

ğŸ¯ Interview One-Liner (Very Important)

â€œAll operations run in O(1) average time using hashing with separate chaining, and degrade to O(n) in the worst case due to collisions. Space complexity is O(n).â€

 */